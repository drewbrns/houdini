{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.vector import count, words\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "from pattern.vector import Document, Model, TFIDF, IG, BINARY\n",
    "from pattern.vector import Vector, distance, tfidf\n",
    "\n",
    "from pattern.en import parse, Sentence, parsetree\n",
    "from pattern.en import wordnet, NOUN, VERB, ADJECTIVE, ADVERB\n",
    "from pattern.en import sentiment\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from textblob import TextBlob\n",
    "# from textblob.wordnet import VERB, Synset\n",
    "\n",
    "PA_WORDS  = ['buy', 'recommend', 'hire', 'have', 'suggest', 'advise', 'want', 'need', 'purchase', 'wish', 'pay']\n",
    "VERB_TAGS = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "NOUN_TAGS = ['NN', 'NNS', 'NNP', 'NNPS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "  {\"text\": \"I need silence, and to be alone and to go out, and to save one hour…\", \"class\": \"non-pi\"},\n",
    "  {\"text\": \"I need more tiaras. I haven't bought a new one in over a year and that's a shame. Send an Amazon gift card so I can fix this today! goddessjoules@gmail.com\", \"class\": \"pi\"},  \n",
    "  {\"text\": \"Hi, recently I was wondering if it pays to buy gtx 1070 or wait for new this year's nvidia graphics cards\", \"class\": \"pi\"},\n",
    "  {\"text\": \"I have been planning for years to immigrate to Canada, the heaven of justice! and now it’s over a year/years that most of #OutlandIranianApplicants are stuck in the assessment limbo of @CitImmCanada. @AhmedDHussen @JustinTrudeau @RalphGoodale @ICCongress\", \"class\": \"non-pi\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Document(data[0]['text'], type=data[0]['class'], stemmer=LEMMA)\n",
    "d2 = Document(data[1]['text'], type=data[1]['class'], stemmer=LEMMA)\n",
    "d3 = Document(data[2]['text'], type=data[2]['class'], stemmer=LEMMA)\n",
    "d4 = Document(data[3]['text'], type=data[3]['class'], stemmer=LEMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(documents=[d1, d2, d3, d4], weight=TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'silence': 1.3862952936151878},\n",
       " {'tiara': 0.1540328104016875,\n",
       "  't': 0.1540328104016875,\n",
       "  'bought': 0.1540328104016875,\n",
       "  'shame': 0.1540328104016875,\n",
       "  'send': 0.1540328104016875,\n",
       "  'amazon': 0.1540328104016875,\n",
       "  'gift': 0.1540328104016875,\n",
       "  'card': 0.07701640520084375,\n",
       "  'fix': 0.1540328104016875},\n",
       " {'hi': 0.12602684487410798,\n",
       "  'recently': 0.12602684487410798,\n",
       "  'wondering': 0.12602684487410798,\n",
       "  'pay': 0.12602684487410798,\n",
       "  'buy': 0.12602684487410798,\n",
       "  'gtx': 0.12602684487410798,\n",
       "  '1070': 0.12602684487410798,\n",
       "  'wait': 0.12602684487410798,\n",
       "  'nvidium': 0.12602684487410798,\n",
       "  'graphic': 0.12602684487410798,\n",
       "  'card': 0.06301342243705399},\n",
       " {'planning': 0.09902109240108484,\n",
       "  'immigrate': 0.09902109240108484,\n",
       "  'canada': 0.09902109240108484,\n",
       "  'heaven': 0.09902109240108484,\n",
       "  'justice': 0.09902109240108484,\n",
       "  'outlandiranianapplicant': 0.09902109240108484,\n",
       "  'stuck': 0.09902109240108484,\n",
       "  'assessment': 0.09902109240108484,\n",
       "  'limbo': 0.09902109240108484,\n",
       "  'citimmcanada': 0.09902109240108484,\n",
       "  'ahmeddhussen': 0.09902109240108484,\n",
       "  'justintrudeau': 0.09902109240108484,\n",
       "  'ralphgoodale': 0.09902109240108484,\n",
       "  'iccongres': 0.09902109240108484}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-pi', 'pi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf-idf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.df('buy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3862952936151878"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.idf('buy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.similarity(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.similarity(d1, d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.similarity(d1, d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027186362391351835"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.similarity(d2, d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.similarity(d2, d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.similarity(d3, d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': 0.12602684487410798,\n",
       " 'recently': 0.12602684487410798,\n",
       " 'wondering': 0.12602684487410798,\n",
       " 'pay': 0.12602684487410798,\n",
       " 'buy': 0.12602684487410798,\n",
       " 'gtx': 0.12602684487410798,\n",
       " '1070': 0.12602684487410798,\n",
       " 'wait': 0.12602684487410798,\n",
       " 'nvidium': 0.12602684487410798,\n",
       " 'graphic': 0.12602684487410798,\n",
       " 'card': 0.06301342243705399}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'silence': 1.9218146410996197},\n",
       " {'tiara': 0.21353496012217993,\n",
       "  't': 0.21353496012217993,\n",
       "  'bought': 0.21353496012217993,\n",
       "  'shame': 0.21353496012217993,\n",
       "  'send': 0.21353496012217993,\n",
       "  'amazon': 0.21353496012217993,\n",
       "  'gift': 0.21353496012217993,\n",
       "  'card': 0.05338374003054498,\n",
       "  'fix': 0.21353496012217993},\n",
       " {'hi': 0.17471042191814726,\n",
       "  'recently': 0.17471042191814726,\n",
       "  'wondering': 0.17471042191814726,\n",
       "  'pay': 0.17471042191814726,\n",
       "  'buy': 0.17471042191814726,\n",
       "  'gtx': 0.17471042191814726,\n",
       "  '1070': 0.17471042191814726,\n",
       "  'wait': 0.17471042191814726,\n",
       "  'nvidium': 0.17471042191814726,\n",
       "  'graphic': 0.17471042191814726,\n",
       "  'card': 0.043677605479536814},\n",
       " {'planning': 0.13727247436425855,\n",
       "  'immigrate': 0.13727247436425855,\n",
       "  'canada': 0.13727247436425855,\n",
       "  'heaven': 0.13727247436425855,\n",
       "  'justice': 0.13727247436425855,\n",
       "  'outlandiranianapplicant': 0.13727247436425855,\n",
       "  'stuck': 0.13727247436425855,\n",
       "  'assessment': 0.13727247436425855,\n",
       "  'limbo': 0.13727247436425855,\n",
       "  'citimmcanada': 0.13727247436425855,\n",
       "  'ahmeddhussen': 0.13727247436425855,\n",
       "  'justintrudeau': 0.13727247436425855,\n",
       "  'ralphgoodale': 0.13727247436425855,\n",
       "  'iccongres': 0.13727247436425855}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf([d1.vector, d2.vector, d3.vector, d4.vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(word_list):\n",
    "    if not isinstance(word_list, list):\n",
    "        raise (TypeError, '`word_list` argument must be a list')\n",
    "    return [\n",
    "        word for word in word_list if word not in set(stopwords.words('english'))\n",
    "        ]\n",
    "\n",
    "def extract_pos(blob, POS_TAGS):\n",
    "    if not isinstance(blob, TextBlob):\n",
    "        raise (TypeError, '`blob` argument must be a TextBlob')\n",
    "    if not isinstance(POS_TAGS, list):\n",
    "        raise (TypeError, '`POS_TAGS` argument must be a list')        \n",
    "    return filter(lambda x: x[1] in POS_TAGS, blob.tags)\n",
    "\n",
    "def extract_terms(blob, pos):\n",
    "    if pos.lower() == 'verb' or pos.lower() == 'vb':\n",
    "        verbs = extract_pos(blob, VERB_TAGS)\n",
    "        return [x[0] for x in verbs]\n",
    "    elif pos.lower() == 'noun' or pos.lower() == 'nn':\n",
    "        nouns = extract_pos(blob, NOUN_TAGS)\n",
    "        return [x[0] for x in nouns]\n",
    "    elif pos.lower() == 'pronoun' or pos.lower() == 'pn':\n",
    "        raise(Exception('Not implemented'))\n",
    "    elif pos.lower() == 'adjective' or pos.lower() == 'adj':\n",
    "        raise(Exception('Not implemented'))\n",
    "    elif pos.lower() == 'adverb' or pos.lower() == 'adv':\n",
    "        raise(Exception('Not implemented'))\n",
    "    elif pos.lower() == 'preposition' or pos.lower() == 'pre':\n",
    "        raise(Exception('Not implemented'))\n",
    "    elif pos.lower() == 'conjunction' or pos.lower() == 'cn':\n",
    "        raise(Exception('Not implemented'))\n",
    "    elif pos.lower() == 'interjection' or pos.lower() == 'in':\n",
    "        raise(Exception('Not implemented'))\n",
    "    else:\n",
    "        raise(Exception('Please provide valid pos. verb, noun, pronoun, adjective')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3 = TextBlob(data[2]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Hi, recently I was wondering if it pays to buy gtx 1070 or wait for new this year's nvidia graphics cards\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = extract_terms(b3, 'verb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['was', 'wondering', 'pays', 'buy', 'wait']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = wordnet.synsets('bird')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('bird.n.01')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bird.n.01'),\n",
       " Synset('bird.n.02'),\n",
       " Synset('dame.n.01'),\n",
       " Synset('boo.n.01'),\n",
       " Synset('shuttlecock.n.01')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_synsets = wordnet.synsets('bird')\n",
    "bird_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_1 = wordnet.synsets('buy', pos=VERB)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_2 = wordnet.synsets('buy', pos=VERB)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obtain by purchase; acquire by means of a financial transaction'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_1.gloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buy', 'purchase']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_1.synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_1.similarity(synset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06818181818181818"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(data[2]['text'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = data[2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parse(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word', 'part-of-speech', 'chunk', 'preposition']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi, recently I was wondering if it pays to buy gtx 1070 or wait for new this year's nvidia graphics cards\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Hi', 'UH', 'O', 'O'],\n",
       "  [',', ',', 'O', 'O'],\n",
       "  ['recently', 'RB', 'B-ADVP', 'O'],\n",
       "  ['I', 'PRP', 'B-NP', 'O'],\n",
       "  ['was', 'VBD', 'B-VP', 'O'],\n",
       "  ['wondering', 'VBG', 'I-VP', 'O'],\n",
       "  ['if', 'IN', 'B-PP', 'B-PNP'],\n",
       "  ['it', 'PRP', 'B-NP', 'I-PNP'],\n",
       "  ['pays', 'VBZ', 'B-VP', 'O'],\n",
       "  ['to', 'TO', 'I-VP', 'O'],\n",
       "  ['buy', 'VB', 'I-VP', 'O'],\n",
       "  ['gtx', 'NN', 'B-NP', 'O'],\n",
       "  ['1070', 'CD', 'I-NP', 'O'],\n",
       "  ['or', 'CC', 'I-NP', 'O'],\n",
       "  ['wait', 'NN', 'I-NP', 'O'],\n",
       "  ['for', 'IN', 'B-PP', 'O'],\n",
       "  ['new', 'JJ', 'B-ADJP', 'O'],\n",
       "  ['this', 'DT', 'B-NP', 'O'],\n",
       "  ['year', 'NN', 'I-NP', 'O'],\n",
       "  [\"'s\", 'POS', 'O', 'O'],\n",
       "  ['nvidia', 'NN', 'B-NP', 'O'],\n",
       "  ['graphics', 'NNS', 'I-NP', 'O'],\n",
       "  ['cards', 'NNS', 'I-NP', 'O']]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(doc3).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = parsetree(doc3, relations=True, lemmata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = s[0].chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String : recently\n",
      "Type   : ADVP\n",
      "Role   : None\n",
      "Related: []\n",
      "Head   : []\n",
      "\n",
      "String : I\n",
      "Type   : NP\n",
      "Role   : SBJ\n",
      "Related: [Chunk('was wondering/VP-1')]\n",
      "Head   : [Chunk('was wondering/VP-1')]\n",
      "\n",
      "String : was wondering\n",
      "Type   : VP\n",
      "Role   : None\n",
      "Related: [Chunk('I/NP-SBJ-1')]\n",
      "Head   : [Chunk('I/NP-SBJ-1')]\n",
      "\n",
      "String : if\n",
      "Type   : PP\n",
      "Role   : None\n",
      "Related: []\n",
      "Head   : []\n",
      "\n",
      "String : it\n",
      "Type   : NP\n",
      "Role   : SBJ\n",
      "Related: [Chunk('pays to buy/VP-2'), Chunk('gtx 1070 or wait/NP-OBJ-2')]\n",
      "Head   : [Chunk('pays to buy/VP-2'), Chunk('gtx 1070 or wait/NP-OBJ-2')]\n",
      "\n",
      "String : pays to buy\n",
      "Type   : VP\n",
      "Role   : None\n",
      "Related: [Chunk('it/NP-SBJ-2'), Chunk('gtx 1070 or wait/NP-OBJ-2')]\n",
      "Head   : [Chunk('it/NP-SBJ-2'), Chunk('gtx 1070 or wait/NP-OBJ-2')]\n",
      "\n",
      "String : gtx 1070 or wait\n",
      "Type   : NP\n",
      "Role   : OBJ\n",
      "Related: [Chunk('it/NP-SBJ-2'), Chunk('pays to buy/VP-2')]\n",
      "Head   : [Chunk('it/NP-SBJ-2'), Chunk('pays to buy/VP-2')]\n",
      "\n",
      "String : for\n",
      "Type   : PP\n",
      "Role   : None\n",
      "Related: []\n",
      "Head   : []\n",
      "\n",
      "String : new\n",
      "Type   : ADJP\n",
      "Role   : None\n",
      "Related: []\n",
      "Head   : []\n",
      "\n",
      "String : this year\n",
      "Type   : NP\n",
      "Role   : None\n",
      "Related: []\n",
      "Head   : []\n",
      "\n",
      "String : nvidia graphics cards\n",
      "Type   : NP\n",
      "Role   : None\n",
      "Related: []\n",
      "Head   : []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(\"String :\", chunk.string)\n",
    "    print(\"Type   :\", chunk.type)\n",
    "    print(\"Role   :\", chunk.role)\n",
    "    print(\"Related:\", chunk.related)\n",
    "    print(\"Head   :\", chunk.related)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ado(document):\n",
    "    s = parsetree(document, relations=True, lemmata=True)\n",
    "    for sent in s:\n",
    "        for chunk in sent.chunks:\n",
    "            if chunk.type == 'VP':\n",
    "                print(\"Subject          : \", chunk.subject)            \n",
    "                print(\"[VP]             : \", chunk.string)\n",
    "                print(\"[VP] [WORDS]     : \", chunk.words)       \n",
    "                if chunk.object is not None:\n",
    "                    print(\"Object [WORDS]   : \", chunk.object.words)\n",
    "                    nouns = filter(lambda x: x.type in NOUN_TAGS, chunk.object.words)        \n",
    "                    nouns = set([noun.string for noun in nouns])\n",
    "                    print(\"Extracted Nouns  :\", nouns)\n",
    "                else:\n",
    "                    print(\"Object           : \", chunk.object)            \n",
    "                print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_verbs(document):        \n",
    "    blob = TextBlob(document)        \n",
    "    tags = filter(lambda x: x[1] in VERB_TAGS, blob.tags)            \n",
    "    return [verb[0] for verb in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['was', 'wondering', 'pays', 'buy', 'wait']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_verbs(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_pa_similarity( word ):\n",
    "    s = wordnet.synsets(word, pos=VERB)[0]\n",
    "\n",
    "    similarities = []\n",
    "    append_sim = similarities.append\n",
    "\n",
    "    for paword in PA_WORDS:\n",
    "        pa_s = wordnet.synsets(paword, pos=VERB)[0]\n",
    "        append_sim( s.similarity(pa_s) )\n",
    "\n",
    "    print(similarities)\n",
    "    return max(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_pa_similarity('buy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_pa_similarity('purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_pa_similarity('pay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5654954205996426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5654954205996426, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5654954205996426"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_pa_similarity('obtain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('obtain.v.01'), Synset('receive.v.02'), Synset('prevail.v.02')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets('obtain', pos=VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_verbs = _get_verbs(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_rows = len(extracted_verbs)\n",
    "count_columns = len(PA_WORDS)\n",
    "frame = DataFrame(np.empty((count_rows, count_columns)), index=extracted_verbs, columns=PA_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>recommend</th>\n",
       "      <th>hire</th>\n",
       "      <th>have</th>\n",
       "      <th>suggest</th>\n",
       "      <th>advise</th>\n",
       "      <th>want</th>\n",
       "      <th>need</th>\n",
       "      <th>purchase</th>\n",
       "      <th>wish</th>\n",
       "      <th>pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>6.931999e-310</td>\n",
       "      <td>1.122473e-316</td>\n",
       "      <td>4.207069e-310</td>\n",
       "      <td>7.764465e+69</td>\n",
       "      <td>1.685826e-312</td>\n",
       "      <td>2.561371e-300</td>\n",
       "      <td>1.333605e+241</td>\n",
       "      <td>1.735326e-309</td>\n",
       "      <td>1.807805e+60</td>\n",
       "      <td>1.855586e-312</td>\n",
       "      <td>5.216755e-307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wondering</th>\n",
       "      <td>-3.384608e+125</td>\n",
       "      <td>3.690289e+180</td>\n",
       "      <td>1.199333e-302</td>\n",
       "      <td>1.094038e-303</td>\n",
       "      <td>1.433734e-298</td>\n",
       "      <td>1.184992e-303</td>\n",
       "      <td>1.823153e-303</td>\n",
       "      <td>1.184994e-303</td>\n",
       "      <td>1.093850e-303</td>\n",
       "      <td>1.002710e-303</td>\n",
       "      <td>8.204348e-304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pays</th>\n",
       "      <td>4.681025e-188</td>\n",
       "      <td>5.997930e+19</td>\n",
       "      <td>2.710567e-24</td>\n",
       "      <td>3.796058e+77</td>\n",
       "      <td>1.634523e+87</td>\n",
       "      <td>2.657113e+82</td>\n",
       "      <td>3.212263e+106</td>\n",
       "      <td>5.038551e-111</td>\n",
       "      <td>4.720251e+154</td>\n",
       "      <td>9.249271e-304</td>\n",
       "      <td>9.251051e-304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy</th>\n",
       "      <td>1.250207e+63</td>\n",
       "      <td>8.298721e-304</td>\n",
       "      <td>1.272151e-178</td>\n",
       "      <td>5.516117e-294</td>\n",
       "      <td>4.262554e+24</td>\n",
       "      <td>9.714609e+303</td>\n",
       "      <td>3.738515e-217</td>\n",
       "      <td>5.545157e-294</td>\n",
       "      <td>9.604798e+303</td>\n",
       "      <td>3.770047e-265</td>\n",
       "      <td>3.594492e-289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait</th>\n",
       "      <td>1.093077e+145</td>\n",
       "      <td>8.245237e-304</td>\n",
       "      <td>9.115710e-304</td>\n",
       "      <td>7.168650e-299</td>\n",
       "      <td>5.567341e-294</td>\n",
       "      <td>3.882846e+130</td>\n",
       "      <td>5.633431e+255</td>\n",
       "      <td>1.391582e+116</td>\n",
       "      <td>3.247651e+106</td>\n",
       "      <td>3.311374e-183</td>\n",
       "      <td>2.213414e-321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     buy      recommend           hire           have  \\\n",
       "was        6.931999e-310  1.122473e-316  4.207069e-310   7.764465e+69   \n",
       "wondering -3.384608e+125  3.690289e+180  1.199333e-302  1.094038e-303   \n",
       "pays       4.681025e-188   5.997930e+19   2.710567e-24   3.796058e+77   \n",
       "buy         1.250207e+63  8.298721e-304  1.272151e-178  5.516117e-294   \n",
       "wait       1.093077e+145  8.245237e-304  9.115710e-304  7.168650e-299   \n",
       "\n",
       "                 suggest         advise           want           need  \\\n",
       "was        1.685826e-312  2.561371e-300  1.333605e+241  1.735326e-309   \n",
       "wondering  1.433734e-298  1.184992e-303  1.823153e-303  1.184994e-303   \n",
       "pays        1.634523e+87   2.657113e+82  3.212263e+106  5.038551e-111   \n",
       "buy         4.262554e+24  9.714609e+303  3.738515e-217  5.545157e-294   \n",
       "wait       5.567341e-294  3.882846e+130  5.633431e+255  1.391582e+116   \n",
       "\n",
       "                purchase           wish            pay  \n",
       "was         1.807805e+60  1.855586e-312  5.216755e-307  \n",
       "wondering  1.093850e-303  1.002710e-303  8.204348e-304  \n",
       "pays       4.720251e+154  9.249271e-304  9.251051e-304  \n",
       "buy        9.604798e+303  3.770047e-265  3.594492e-289  \n",
       "wait       3.247651e+106  3.311374e-183  2.213414e-321  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for verb in extracted_verbs:\n",
    "    s = wordnet.synsets(verb, pos=VERB)[0]               \n",
    "    for paword in PA_WORDS:\n",
    "        pa_s = wordnet.synsets(paword, pos=VERB)[0]                \n",
    "        frame[paword][verb] = s.similarity(pa_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>recommend</th>\n",
       "      <th>hire</th>\n",
       "      <th>have</th>\n",
       "      <th>suggest</th>\n",
       "      <th>advise</th>\n",
       "      <th>want</th>\n",
       "      <th>need</th>\n",
       "      <th>purchase</th>\n",
       "      <th>wish</th>\n",
       "      <th>pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wondering</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pays</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           buy  recommend  hire  have  suggest    advise  want  need  \\\n",
       "was        0.0        0.0   0.0   0.0      0.0  0.000000   0.0   0.0   \n",
       "wondering  0.0        0.0   0.0   0.0      0.0  0.360471   0.0   0.0   \n",
       "pays       0.0        0.0   0.0   0.0      0.0  0.000000   0.0   0.0   \n",
       "buy        1.0        0.0   0.0   0.0      0.0  0.000000   0.0   0.0   \n",
       "wait       0.0        0.0   0.0   0.0      0.0  0.000000   0.0   0.0   \n",
       "\n",
       "           purchase  wish  pay  \n",
       "was             0.0   0.0  0.0  \n",
       "wondering       0.0   0.0  0.0  \n",
       "pays            0.0   0.0  1.0  \n",
       "buy             1.0   0.0  0.0  \n",
       "wait            0.0   0.0  0.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpa_max_columns = frame.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buy          1.000000\n",
       "recommend    0.000000\n",
       "hire         0.000000\n",
       "have         0.000000\n",
       "suggest      0.000000\n",
       "advise       0.360471\n",
       "want         0.000000\n",
       "need         0.000000\n",
       "purchase     1.000000\n",
       "wish         0.000000\n",
       "pay          1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpa_max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.6000000000000001)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('What are some good places to have lunch in Palo Alto?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    if i == 3:\n",
    "        break\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = \"I want to purchase a new phone, should i go for the iphone x or google pixel?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject          :  I\n",
      "[VP]             :  was wondering\n",
      "[VP] [WORDS]     :  [Word('was/VBD'), Word('wondering/VBG')]\n",
      "Object           :  None\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  it\n",
      "[VP]             :  pays to buy\n",
      "[VP] [WORDS]     :  [Word('pays/VBZ'), Word('to/TO'), Word('buy/VB')]\n",
      "Object [WORDS]   :  [Word('gtx/NN'), Word('1070/CD'), Word('or/CC'), Word('wait/NN')]\n",
      "Extracted Nouns  : {'gtx', 'wait'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "find_ado(data[2]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject          :  I\n",
      "[VP]             :  want to purchase\n",
      "[VP] [WORDS]     :  [Word('want/VBP'), Word('to/TO'), Word('purchase/VB')]\n",
      "Object [WORDS]   :  [Word('a/DT'), Word('new/JJ'), Word('phone/NN')]\n",
      "Extracted Nouns  : {'phone'}\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  None\n",
      "[VP]             :  should i go\n",
      "[VP] [WORDS]     :  [Word('should/MD'), Word('i/VB'), Word('go/VB')]\n",
      "Object           :  None\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "find_ado(doc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject          :  I\n",
      "[VP]             :  have been planning\n",
      "[VP] [WORDS]     :  [Word('have/VBP'), Word('been/VBN'), Word('planning/VBG')]\n",
      "Object           :  None\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  years\n",
      "[VP]             :  to immigrate\n",
      "[VP] [WORDS]     :  [Word('to/TO'), Word('immigrate/VB')]\n",
      "Object           :  None\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  OutlandIranianApplicants\n",
      "[VP]             :  are stuck\n",
      "[VP] [WORDS]     :  [Word('are/VBP'), Word('stuck/VBN')]\n",
      "Object           :  None\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  None\n",
      "[VP]             :  @AhmedDHussen\n",
      "[VP] [WORDS]     :  [Word('@AhmedDHussen/VBN')]\n",
      "Object [WORDS]   :  [Word('@JustinTrudeau/NN'), Word('@RalphGoodale/NN'), Word('@ICCongress/NN')]\n",
      "Extracted Nouns  : {'@ICCongress', '@RalphGoodale', '@JustinTrudeau'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "find_ado(data[3]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have been planning for years to immigrate to Canada, the heaven of justice! and now it’s over a year/years that most of #OutlandIranianApplicants are stuck in the assessment limbo of @CitImmCanada. @AhmedDHussen @JustinTrudeau @RalphGoodale @ICCongress'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject          :  I\n",
      "[VP]             :  need\n",
      "[VP] [WORDS]     :  [Word('need/VBP')]\n",
      "Object [WORDS]   :  [Word('more/JJR'), Word('tiaras/NNS')]\n",
      "Extracted Nouns  : {'tiaras'}\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  I\n",
      "[VP]             :  have n't bought\n",
      "[VP] [WORDS]     :  [Word('have/VBP'), Word(\"n't/RB\"), Word('bought/VBN')]\n",
      "Object           :  None\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  None\n",
      "[VP]             :  's\n",
      "[VP] [WORDS]     :  [Word(\"'s/VBZ\")]\n",
      "Object [WORDS]   :  [Word('a/DT'), Word('shame/NN')]\n",
      "Extracted Nouns  : {'shame'}\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  None\n",
      "[VP]             :  Send\n",
      "[VP] [WORDS]     :  [Word('Send/VB')]\n",
      "Object [WORDS]   :  [Word('an/DT'), Word('Amazon/NNP'), Word('gift/NN'), Word('card/NN')]\n",
      "Extracted Nouns  : {'card', 'gift', 'Amazon'}\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  I\n",
      "[VP]             :  can fix\n",
      "[VP] [WORDS]     :  [Word('can/MD'), Word('fix/VB')]\n",
      "Object [WORDS]   :  [Word('this/DT'), Word('today/NN')]\n",
      "Extracted Nouns  : {'today'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "find_ado(data[1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I need more tiaras. I haven't bought a new one in over a year and that's a shame. Send an Amazon gift card so I can fix this today! goddessjoules@gmail.com\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc6 = \"Can you please recommend some good place to have lunch in Bangalore?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6 = TextBlob(doc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Can', 'MD'),\n",
       " ('you', 'PRP'),\n",
       " ('please', 'VB'),\n",
       " ('recommend', 'VB'),\n",
       " ('some', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('place', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('lunch', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Bangalore', 'NNP')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b6.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject          :  None\n",
      "[VP]             :  Can\n",
      "[VP] [WORDS]     :  [Word('Can/MD')]\n",
      "Object [WORDS]   :  [Word('you/PRP')]\n",
      "Extracted Nouns  : set()\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  you\n",
      "[VP]             :  please recommend\n",
      "[VP] [WORDS]     :  [Word('please/VB'), Word('recommend/VB')]\n",
      "Object [WORDS]   :  [Word('some/DT'), Word('good/JJ'), Word('place/NN')]\n",
      "Extracted Nouns  : {'place'}\n",
      "--------------------------------------------------------------------------------\n",
      "Subject          :  some good place\n",
      "[VP]             :  to have\n",
      "[VP] [WORDS]     :  [Word('to/TO'), Word('have/VB')]\n",
      "Object [WORDS]   :  [Word('lunch/NN')]\n",
      "Extracted Nouns  : {'lunch'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "find_ado(doc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  Can\n",
      "WORDS    :  [Word('Can/MD')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  you\n",
      "WORDS    :  [Word('you/PRP')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  please recommend\n",
      "WORDS    :  [Word('please/VB'), Word('recommend/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  some good place\n",
      "WORDS    :  [Word('some/DT'), Word('good/JJ'), Word('place/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  to have\n",
      "WORDS    :  [Word('to/TO'), Word('have/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  lunch\n",
      "WORDS    :  [Word('lunch/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  PP\n",
      "PNP      :  in Bangalore\n",
      "STRING   :  in\n",
      "WORDS    :  [Word('in/IN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  in Bangalore\n",
      "STRING   :  Bangalore\n",
      "WORDS    :  [Word('Bangalore/NNP')]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "s = parsetree(doc6, relations=True, lemmata=True)\n",
    "for sent in s:\n",
    "    for chunk in sent.chunks:\n",
    "        print('TYPE     : ', chunk.type)\n",
    "        print('PNP      : ', chunk.pnp)\n",
    "        print(\"STRING   : \", chunk.string)\n",
    "        print(\"WORDS    : \", chunk.words)       \n",
    "        print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  I\n",
      "WORDS    :  [Word('I/PRP')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  want to purchase\n",
      "WORDS    :  [Word('want/VBP'), Word('to/TO'), Word('purchase/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  a new phone\n",
      "WORDS    :  [Word('a/DT'), Word('new/JJ'), Word('phone/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  should i go\n",
      "WORDS    :  [Word('should/MD'), Word('i/VB'), Word('go/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  PP\n",
      "PNP      :  for the iphone x\n",
      "STRING   :  for\n",
      "WORDS    :  [Word('for/IN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  for the iphone x\n",
      "STRING   :  the iphone x\n",
      "WORDS    :  [Word('the/DT'), Word('iphone/NNP'), Word('x/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  google pixel\n",
      "WORDS    :  [Word('google/NNP-ORG'), Word('pixel/NN')]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "s = parsetree(doc5, relations=True, lemmata=True)\n",
    "for sent in s:\n",
    "    for chunk in sent.chunks:\n",
    "        print('TYPE     : ', chunk.type)\n",
    "        print('PNP      : ', chunk.pnp)\n",
    "        print(\"STRING   : \", chunk.string)\n",
    "        print(\"WORDS    : \", chunk.words)       \n",
    "        print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_psd(doc):\n",
    "    s = parsetree(doc, relations=True, lemmata=True)\n",
    "    for sent in s:\n",
    "        for chunk in sent.chunks:\n",
    "            print('TYPE     : ', chunk.type)\n",
    "            print('PNP      : ', chunk.pnp)\n",
    "            print(\"STRING   : \", chunk.string)\n",
    "            print(\"WORDS    : \", chunk.words)       \n",
    "            print('-'*80)\n",
    "        print(sent.chunks)\n",
    "        print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  Can\n",
      "WORDS    :  [Word('Can/MD')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  you\n",
      "WORDS    :  [Word('you/PRP')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  please recommend\n",
      "WORDS    :  [Word('please/VB'), Word('recommend/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  some good place\n",
      "WORDS    :  [Word('some/DT'), Word('good/JJ'), Word('place/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  to have\n",
      "WORDS    :  [Word('to/TO'), Word('have/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  lunch\n",
      "WORDS    :  [Word('lunch/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  PP\n",
      "PNP      :  in Bangalore\n",
      "STRING   :  in\n",
      "WORDS    :  [Word('in/IN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  in Bangalore\n",
      "STRING   :  Bangalore\n",
      "WORDS    :  [Word('Bangalore/NNP')]\n",
      "--------------------------------------------------------------------------------\n",
      "[Chunk('Can/VP-1'), Chunk('you/NP-OBJ-1'), Chunk('please recommend/VP-2'), Chunk('some good place/NP-OBJ-2'), Chunk('to have/VP-3'), Chunk('lunch/NP-OBJ-3'), Chunk('in/PP'), Chunk('Bangalore/NP')]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "extract_psd(doc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  I\n",
      "WORDS    :  [Word('I/PRP')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  want to purchase\n",
      "WORDS    :  [Word('want/VBP'), Word('to/TO'), Word('purchase/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  a new phone\n",
      "WORDS    :  [Word('a/DT'), Word('new/JJ'), Word('phone/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  should i go\n",
      "WORDS    :  [Word('should/MD'), Word('i/VB'), Word('go/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  PP\n",
      "PNP      :  for the iphone x\n",
      "STRING   :  for\n",
      "WORDS    :  [Word('for/IN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  for the iphone x\n",
      "STRING   :  the iphone x\n",
      "WORDS    :  [Word('the/DT'), Word('iphone/NNP'), Word('x/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  google pixel\n",
      "WORDS    :  [Word('google/NNP-ORG'), Word('pixel/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "[Chunk('I/NP-SBJ-1'), Chunk('want to purchase/VP-1'), Chunk('a new phone/NP-OBJ-1'), Chunk('should i go/VP'), Chunk('for/PP'), Chunk('the iphone x/NP'), Chunk('google pixel/NP')]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "extract_psd(doc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = data[2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = data[3]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = data[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = data[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE     :  ADVP\n",
      "PNP      :  None\n",
      "STRING   :  recently\n",
      "WORDS    :  [Word('recently/RB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  I\n",
      "WORDS    :  [Word('I/PRP')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  was wondering\n",
      "WORDS    :  [Word('was/VBD'), Word('wondering/VBG')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  PP\n",
      "PNP      :  if it\n",
      "STRING   :  if\n",
      "WORDS    :  [Word('if/IN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  if it\n",
      "STRING   :  it\n",
      "WORDS    :  [Word('it/PRP')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  pays to buy\n",
      "WORDS    :  [Word('pays/VBZ'), Word('to/TO'), Word('buy/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  gtx 1070 or wait\n",
      "WORDS    :  [Word('gtx/NN'), Word('1070/CD'), Word('or/CC'), Word('wait/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  PP\n",
      "PNP      :  None\n",
      "STRING   :  for\n",
      "WORDS    :  [Word('for/IN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  ADJP\n",
      "PNP      :  None\n",
      "STRING   :  new\n",
      "WORDS    :  [Word('new/JJ')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  this year\n",
      "WORDS    :  [Word('this/DT'), Word('year/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  nvidia graphics cards\n",
      "WORDS    :  [Word('nvidia/NN'), Word('graphics/NNS'), Word('cards/NNS')]\n",
      "--------------------------------------------------------------------------------\n",
      "[Chunk('recently/ADVP'), Chunk('I/NP-SBJ-1'), Chunk('was wondering/VP-1'), Chunk('if/PP'), Chunk('it/NP-SBJ-2'), Chunk('pays to buy/VP-2'), Chunk('gtx 1070 or wait/NP-OBJ-2'), Chunk('for/PP'), Chunk('new/ADJP'), Chunk('this year/NP'), Chunk('nvidia graphics cards/NP')]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "extract_psd(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi, recently I was wondering if it pays to buy gtx 1070 or wait for new this year's nvidia graphics cards\""
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  I\n",
      "WORDS    :  [Word('I/PRP')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  want to buy\n",
      "WORDS    :  [Word('want/VBP'), Word('to/TO'), Word('buy/VB')]\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  a phone\n",
      "WORDS    :  [Word('a/DT'), Word('phone/NN')]\n",
      "--------------------------------------------------------------------------------\n",
      "[Chunk('I/NP-SBJ-1'), Chunk('want to buy/VP-1'), Chunk('a phone/NP-OBJ-1')]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "extract_psd(\"I want to buy a phone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  Can\n",
      "OBJECT   :  you\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  you\n",
      "WORDS    :  [Word('you/PRP')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  please recommend\n",
      "OBJECT   :  some good place\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  some good place\n",
      "WORDS    :  [Word('some/DT'), Word('good/JJ'), Word('place/NN')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  to have\n",
      "OBJECT   :  lunch\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  lunch\n",
      "WORDS    :  [Word('lunch/NN')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  PP\n",
      "PNP      :  in Bangalore\n",
      "STRING   :  in\n",
      "WORDS    :  [Word('in/IN')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  in Bangalore\n",
      "STRING   :  Bangalore\n",
      "WORDS    :  [Word('Bangalore/NNP')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "[Chunk('Can/VP-1'), Chunk('you/NP-OBJ-1'), Chunk('please recommend/VP-2'), Chunk('some good place/NP-OBJ-2'), Chunk('to have/VP-3'), Chunk('lunch/NP-OBJ-3'), Chunk('in/PP'), Chunk('Bangalore/NP')]\n"
     ]
    }
   ],
   "source": [
    "s = parsetree(doc6, relations=True, lemmata=True)\n",
    "for sent in s:\n",
    "    for chunk in sent.chunks:\n",
    "        if chunk.type == 'VP' and chunk.object is not None:\n",
    "            print(\"TYPE     : \", chunk.type)            \n",
    "            print(\"PNP      : \", chunk.pnp)\n",
    "            print(\"STRING   : \", chunk.string)            \n",
    "            print(\"OBJECT   : \", chunk.object)            \n",
    "            print('-'*80)            \n",
    "        if chunk.type == \"PP\" or chunk.type == \"NP\":\n",
    "            print(\"TYPE     : \", chunk.type)            \n",
    "            print(\"PNP      : \", chunk.pnp)\n",
    "            print(\"STRING   : \", chunk.string)\n",
    "            print(\"WORDS    : \", chunk.words)\n",
    "            print(\"OBJECT   : \", chunk.object)\n",
    "            print('-'*80)\n",
    "    print(sent.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  are\n",
      "OBJECT   :  some good places\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  some good places\n",
      "WORDS    :  [Word('some/DT'), Word('good/JJ'), Word('places/NNS')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  VP\n",
      "PNP      :  None\n",
      "STRING   :  to have\n",
      "OBJECT   :  lunch\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  None\n",
      "STRING   :  lunch\n",
      "WORDS    :  [Word('lunch/NN')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  PP\n",
      "PNP      :  in Bangalore\n",
      "STRING   :  in\n",
      "WORDS    :  [Word('in/IN')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "TYPE     :  NP\n",
      "PNP      :  in Bangalore\n",
      "STRING   :  Bangalore\n",
      "WORDS    :  [Word('Bangalore/NNP')]\n",
      "OBJECT   :  None\n",
      "--------------------------------------------------------------------------------\n",
      "[Chunk('are/VP-1'), Chunk('some good places/NP-OBJ-1'), Chunk('to have/VP-2'), Chunk('lunch/NP-OBJ-2'), Chunk('in/PP'), Chunk('Bangalore/NP')]\n"
     ]
    }
   ],
   "source": [
    "s = parsetree(\"What are some good places to have lunch in Bangalore?\", relations=True, lemmata=True)\n",
    "for sent in s:\n",
    "    for chunk in sent.chunks:\n",
    "        if chunk.type == 'VP' and chunk.object is not None:\n",
    "            print(\"TYPE     : \", chunk.type)            \n",
    "            print(\"PNP      : \", chunk.pnp)\n",
    "            print(\"STRING   : \", chunk.string)            \n",
    "            print(\"OBJECT   : \", chunk.object)            \n",
    "            print('-'*80)            \n",
    "        if chunk.type == \"PP\" or chunk.type == \"NP\":\n",
    "            print(\"TYPE     : \", chunk.type)            \n",
    "            print(\"PNP      : \", chunk.pnp)\n",
    "            print(\"STRING   : \", chunk.string)\n",
    "            print(\"WORDS    : \", chunk.words)\n",
    "            print(\"OBJECT   : \", chunk.object)\n",
    "            print('-'*80)\n",
    "    print(sent.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
